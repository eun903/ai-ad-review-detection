from typing import Optional
from fastapi import FastAPI
from pydantic import BaseModel
import mysql.connector
import json
import numpy as np
from sentence_transformers import SentenceTransformer
import logging
from sklearn.metrics.pairwise import cosine_similarity
import re

app = FastAPI(title="Ad Review Analyzer API")

logging.basicConfig(level=logging.INFO)

# 1. íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ
logging.info("ğŸš€ Loading fine-tuned MiniLM model...")
model = SentenceTransformer("./finetuned_minilm_model")

# 2. DB ì„¤ì •
DB_CONFIG = {
    "host": "localhost",
    "database": "review_similarity",
    "user": "root",
    "password": "onlyroot",
    "auth_plugin": "mysql_native_password",
    "charset": "utf8mb4"
}

# 3. ì£¼ìš” í‚¤ì›Œë“œ ì •ì˜
AD_KEYWORDS = ['ë¬´ë£Œ', 'ë¬´ë£Œì œê³µ', 'ë¦¬ë·°ì–´', 'ì²´í—˜ë‹¨', 'ë¬´ìƒ', 'í˜‘ì°¬', 'ì´ë²¤íŠ¸', 'ì œí’ˆì œê³µ']
NON_AD_KEYWORDS = ['ë‚´ëˆë‚´ì‚°', 'ì§ì ‘ êµ¬ë§¤', 'ì§ì ‘ êµ¬ì…', 'ê³¼ì¥ê´‘ê³ ', 'ê·¸ë‚˜ë§ˆ', 'ë³„ë¡œ', 'ë„ˆë¬´ ë¹„ì‹¸']
NEGATIVE_PHRASES = ['ë³„ë¡œ', 'ì‹¤ë§', 'ë¹„ìŒˆ', 'í›„íšŒ', 'ëˆ ì•„ê¹Œì›€', 'ë¹„ì¶”', 'ì•ˆ ì¢‹ìŒ', 'ì•ˆ ë¨¹ìŒ']


# DB ì—°ê²° í•¨ìˆ˜
def get_db_connection():
    return mysql.connector.connect(**DB_CONFIG)


# ìš”ì²­ ëª¨ë¸
class ReviewRequest(BaseModel):
    review: Optional[str] = None
    userReview: Optional[str] = None
    category: Optional[str] = None


# ì‘ë‹µ ëª¨ë¸
class ReviewResponse(BaseModel):
    ì…ë ¥_ë¦¬ë·°: str
    ê°€ì¥_ìœ ì‚¬í•œ_ê´‘ê³ _ë¦¬ë·°: str
    ìœ ì‚¬ë„_ì ìˆ˜: float
    label: int
    í›„ë³´_ë¦¬ë·°ë“¤: list
    íŒë‹¨: str
    ê´‘ê³ _í‚¤ì›Œë“œ: list
    ë¹„ê´‘ê³ _í‚¤ì›Œë“œ: list


# # âœ… í‚¤ì›Œë“œ ë§¤ì¹­ í•¨ìˆ˜
# def match_keywords(text: str, keyword_list: list) -> list:
#     return [kw for kw in keyword_list if re.search(r'\b' + re.escape(kw) + r'\b', text)]

def match_keywords(text: str, keyword_list: list) -> list:
    results = []
    
    for kw in keyword_list:
        pattern = re.escape(kw)
        
        if re.search(pattern, text, re.I):
            results.append(kw)
            
    return results

# âœ… ìœ íš¨ì„± ê²€ì¦
def is_valid_review(text: str) -> bool:
    if text is None:
        return False
    text = text.strip()
    if len(text) < 5 or text.isdigit():
        return False
    if all(ch in "!@#$%^&*()_+=-[]{};:'\",.<>?/|" for ch in text):
        return False
    return True


# âœ… ì•ˆì „í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
def safe_cosine_similarity(vec1, vec2):
    denom = (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    if denom == 0:
        return 0.0
    return float(np.dot(vec1, vec2) / denom)


# âœ… í•µì‹¬ ë¶„ì„ í•¨ìˆ˜
def analyze_review(user_review: str, category: Optional[str] = None, top_n=3, threshold=0.7, min_similarity=0.2):
    matched_ad_keywords = match_keywords(user_review, AD_KEYWORDS)
    matched_non_ad_keywords = match_keywords(user_review, NON_AD_KEYWORDS)
    matched_negative_phrases = match_keywords(user_review, NEGATIVE_PHRASES)

    # ë¦¬ë·° ê²€ì¦
    if not is_valid_review(user_review):
        return {
            "ì…ë ¥_ë¦¬ë·°": user_review or "",
            "ê°€ì¥_ìœ ì‚¬í•œ_ê´‘ê³ _ë¦¬ë·°": "",
            "ìœ ì‚¬ë„_ì ìˆ˜": 0.0,
            "label": -1,
            "í›„ë³´_ë¦¬ë·°ë“¤": [],
            "íŒë‹¨": "ë¶„ì„ ë¶ˆê°€ (ë¦¬ë·° ë‚´ìš© ë¶€ì¡±)",
            "ê´‘ê³ _í‚¤ì›Œë“œ": matched_ad_keywords,
            "ë¹„ê´‘ê³ _í‚¤ì›Œë“œ": matched_non_ad_keywords + matched_negative_phrases
        }

    # 1ï¸âƒ£ ì‚¬ìš©ì ë¦¬ë·° ë²¡í„°í™”
    user_vec = model.encode(user_review)

    # 2ï¸âƒ£ DB ì¡°íšŒ
    conn = get_db_connection()
    cur = conn.cursor(dictionary=True)

    if category:
        category = category.strip()  # âœ… ê³µë°± ì œê±°
        logging.info(f"[DB] category filter applied: {category}")
        cur.execute("""
            SELECT cleaned_review, label, review_vector, category
            FROM reviews
            WHERE review_vector IS NOT NULL
            AND review_vector != ''
            AND TRIM(category) = %s
            AND label = 1  -- âœ… ê´‘ê³  ë¦¬ë·°ë§Œ ë¹„êµ
        """, (category,))
    else:
        logging.info("[DB] no category provided â€” loading all ad reviews")
        cur.execute("""
            SELECT cleaned_review, label, review_vector, category
            FROM reviews
            WHERE review_vector IS NOT NULL
            AND review_vector != ''
            AND label = 1
        """)

    rows = cur.fetchall()
    cur.close()
    conn.close()

    logging.info(f"[DB] {len(rows)}ê°œ í›„ë³´ ë¡œë“œë¨ (ì¹´í…Œê³ ë¦¬={category})")
    if rows:
        categories = set([r["category"] for r in rows])
        logging.info(f"[DB] í›„ë³´ ì¹´í…Œê³ ë¦¬ ìƒ˜í”Œ: {list(categories)[:5]}")

    if not rows:
        return {
            "ì…ë ¥_ë¦¬ë·°": user_review,
            "ê°€ì¥_ìœ ì‚¬í•œ_ê´‘ê³ _ë¦¬ë·°": "",
            "ìœ ì‚¬ë„_ì ìˆ˜": 0.0,
            "label": -1,
            "í›„ë³´_ë¦¬ë·°ë“¤": [],
            "íŒë‹¨": "ë°ì´í„° ë¶€ì¡± (í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì—†ìŒ)",
            "ê´‘ê³ _í‚¤ì›Œë“œ": matched_ad_keywords,
            "ë¹„ê´‘ê³ _í‚¤ì›Œë“œ": matched_non_ad_keywords + matched_negative_phrases
        }

    # 3ï¸âƒ£ ìœ ì‚¬ë„ ê³„ì‚°
    candidates = []
    best_score = -1.0
    best_review = ""
    best_label = -1

    for row in rows:
        try:
            review_vec = np.array(json.loads(row["review_vector"]))
            score = safe_cosine_similarity(user_vec, review_vec)
            candidates.append({"review": row["cleaned_review"], "score": float(score), "label": row["label"]})
            if score > best_score:
                best_score = score
                best_review = row["cleaned_review"]
                best_label = row["label"]
        except Exception as e:
            logging.warning(f"âš ï¸ ë²¡í„° íŒŒì‹± ì—ëŸ¬: {e}")
            continue

    candidates.sort(key=lambda x: x["score"], reverse=True)
    top_candidates = candidates[:top_n]

    # 4ï¸âƒ£ í‚¤ì›Œë“œ ê¸°ë°˜ ë³´ì •
    keyword_adjustment = (
        0.05 * len(matched_ad_keywords)
        - 0.1 * len(matched_non_ad_keywords)
        - 0.1 * len(matched_negative_phrases)
    )
    final_score = max(0, min(1, best_score + keyword_adjustment))

    # 5ï¸âƒ£ íŒë‹¨ ë¡œì§
    if final_score < min_similarity:
        decision_text = "ê´‘ê³ ì„±ì´ ì•„ë‹ ê°€ëŠ¥ì„±ì´ ë†’ìŒ"
        best_label = 0
    elif final_score >= threshold:
        decision_text = "ê´‘ê³ ì„± ë¦¬ë·°ì¼ ê°€ëŠ¥ì„± ë†’ìŒ"
        best_label = 1
    else:
        decision_text = "ì¼ë°˜ ë¦¬ë·°ì¼ ê°€ëŠ¥ì„± ë†’ìŒ"
        best_label = 0

    # 6ï¸âƒ£ ê²°ê³¼ ë°˜í™˜
    return {
        "ì…ë ¥_ë¦¬ë·°": user_review,
        "ê°€ì¥_ìœ ì‚¬í•œ_ê´‘ê³ _ë¦¬ë·°": best_review,
        "ìœ ì‚¬ë„_ì ìˆ˜": round(float(final_score) * 100, 2),
        "label": int(best_label),
        "í›„ë³´_ë¦¬ë·°ë“¤": [{"review": c["review"], "score": round(c["score"]*100, 2)} for c in top_candidates],
        "íŒë‹¨": decision_text,
        "ê´‘ê³ _í‚¤ì›Œë“œ": matched_ad_keywords,
        "ë¹„ê´‘ê³ _í‚¤ì›Œë“œ": matched_non_ad_keywords + matched_negative_phrases
    }


# FastAPI ê¸°ë³¸ ë¼ìš°íŠ¸
@app.get("/")
def root():
    return {"message": "FastAPI ì„œë²„ ì •ìƒ ì‘ë™ ì¤‘ ğŸš€"}


# ë¶„ì„ ìš”ì²­
@app.post("/analyze", response_model=ReviewResponse)
def analyze(data: ReviewRequest):
    text = (data.review or data.userReview or "").strip()
    category = data.category
    logging.info(f"ğŸ“¦ ë°›ì€ category ê°’: {category}")
    return analyze_review(text, category)
